{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "from typing import Union, Tuple, Sequence, Set\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    RandomErasing,\n",
    "                                    RandomAutocontrast,\n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    RandomAdjustSharpness,\n",
    "                                    ToTensor)\n",
    "import torch\n",
    "from transformers import AutoFeatureExtractor, TrainingArguments, Trainer\n",
    "from transformers import AutoModelForImageClassification\n",
    "from datasets import load_metric\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "from toolz.dicttoolz import valmap\n",
    "from collections import Counter\n",
    "from toolz import frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration davanstrien--flysheet-2cdc8849e04b41c9\n",
      "Reusing dataset parquet (/Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"davanstrien/flysheet\", use_auth_token=True, streaming=False, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =  '/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r (1).jpg.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r (1).jpg.jpg'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = re.sub(r\"(\\(\\d\\))\",\"\",f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_base_path_deduplicated(x):\n",
    "    f = x['fpath']\n",
    "    f = re.sub(r\"(\\(\\d\\))\",\"\",f)\n",
    "    f = f.split(\".\")[0]\n",
    "    f = f.rstrip()\n",
    "    return {\"clean_path\": re.sub(r\"(\\(\\d\\))\",\"\",f)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_uniques(example, uniques, column='clean_path'):\n",
    "    if example[column] in uniques:\n",
    "        uniques.remove(example[column])\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label', 'fpath'],\n",
       "    num_rows: 2061\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(ds):\n",
    "    ds = ds.map(return_base_path_deduplicated)\n",
    "    uniques = set(ds['clean_path'])\n",
    "    ds = ds.filter(check_uniques, fn_kwargs={\"uniques\":uniques})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c088e7319c45d18fd0b5a9652aa87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcd3fbb504f40ed977f51a329ad6cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = drop_duplicates(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(example):\n",
    "    x = example[\"fpath\"]\n",
    "    x = Path(x).name.split(\"_\")\n",
    "    return {\"id\": \"_\".join(x[:2] if len(x) >= 3 else x[:3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765c9ac575344282b319c0a09b4e29dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(get_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=448x248 at 0x19DE98940>,\n",
       " 'label': 0,\n",
       " 'fpath': '/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/add_ms_10455_fse005r.jpg',\n",
       " 'clean_path': '/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/add_ms_10455_fse005r',\n",
       " 'id': 'add_ms'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label', 'fpath', 'clean_path', 'id'],\n",
       "    num_rows: 1223\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, valid, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_w_stratify(\n",
    "    ds,\n",
    "    test_size: Union[int, float],\n",
    "    train_size: Union[int, float, None] = None,\n",
    "    random_state: Union[int, RandomState, None] = None,\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    labels = ds['label']\n",
    "    label_array = np.array(labels)\n",
    "    train_inds, valid_inds = next(\n",
    "        StratifiedShuffleSplit(\n",
    "            n_splits=2, test_size=test_size, random_state=random_state\n",
    "        ).split(np.zeros(len(labels)), y=label_array)\n",
    "    )\n",
    "    return ds.select(train_inds), ds.select(valid_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = split_w_stratify(ds, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allclose(train.shape, valid.shape,rtol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 25, 2: 108, 3: 93, 0: 36, 6: 139, 1: 30, 4: 164, 7: 16}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_freqs = frequencies(train['label'])\n",
    "train_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([4.5, 3.75, 13.5, 11.625, 20.5, 3.125, 17.375, 2.0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_percentages =  OrderedDict(sorted(valmap(lambda x: x/len(train_freqs),train_freqs).items())).values()\n",
    "train_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([4.5, 3.625, 13.625, 11.75, 20.625, 3.125, 17.375, 1.875])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_freqs = frequencies(valid['label'])\n",
    "valid_percentages = OrderedDict(sorted(valmap(lambda x: x/len(valid_freqs),valid_freqs).items())).values()\n",
    "valid_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allclose(list(train_percentages), list(valid_percentages), atol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train_valid_split_w_stratify(\n",
    "    ds,\n",
    "    valid_size: Union[int,float]=None,\n",
    "    test_size: Union[int, float]=0.3,\n",
    "    train_size: Union[int, float, None] = None,\n",
    "    random_state: Union[int, RandomState, None] = None,\n",
    ") -> Tuple[Dataset,Dataset, Dataset]:\n",
    "    train, valid_test = split_w_stratify(ds, test_size=test_size)\n",
    "    valid, test = split_w_stratify(valid_test, test_size=test_size)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = train_valid_split_w_stratify(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(ds):\n",
    "    print(\"Preparing dataset...\")\n",
    "    print(\"dropping duplicates...\")\n",
    "    ds = drop_duplicates(ds)\n",
    "    print(\"getting ID...\")\n",
    "    ds = ds.map(get_id)    \n",
    "    print(\"creating train, valid, test splits...\")\n",
    "    train, valid, test = train_valid_split_w_stratify(ds)\n",
    "    data = {\"train\": train, \n",
    "            \"valid\": valid, \n",
    "            \"test\": test}\n",
    "    for k,v  in data.items():\n",
    "        print(f\"{k} has {len(v)} examples\")\n",
    "    return train,valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration davanstrien--flysheet-2cdc8849e04b41c9\n",
      "Reusing dataset parquet (/Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"davanstrien/flysheet\", use_auth_token=True, streaming=False, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dropping duplicates<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "dropping duplicates\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-1dfba86c98cf68e0.arrow\n",
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-f34fde9b42e1bc61.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">getting ID<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "getting ID\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-3c87c3e3b7dda5fa.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">creating train, valid, test splits<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "creating train, valid, test splits\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">856</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "train has \u001b[1;36m856\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">valid has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "valid has \u001b[1;36m256\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test has \u001b[1;36m111\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['image', 'label', 'fpath', 'clean_path', 'id'],\n",
       "     num_rows: 856\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['image', 'label', 'fpath', 'clean_path', 'id'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['image', 'label', 'fpath', 'clean_path', 'id'],\n",
       "     num_rows: 111\n",
       " }))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,valid,test = prepare_dataset(ds)\n",
    "train,valid,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"davanstrien/vit-base-patch16-224-in21k-base-manuscripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_transforms(model_checkpoint, train_ds, valid_ds, test_ds=None):\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "    normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "    _train_transforms = Compose(\n",
    "            [\n",
    "                Resize((feature_extractor.size,feature_extractor.size)),\n",
    "                RandomAdjustSharpness(0.1),\n",
    "                RandomAutocontrast(),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "                RandomErasing()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    _val_transforms = Compose(\n",
    "            [\n",
    "                Resize((feature_extractor.size, feature_extractor.size)),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def train_transforms(examples):\n",
    "        examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "        return examples\n",
    "\n",
    "    def val_transforms(examples):\n",
    "        examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "        return examples\n",
    "    if test_ds is not None:\n",
    "        test_ds.set_transform(val_transforms)\n",
    "    train_ds.set_transform(train_transforms)\n",
    "    valid_ds.set_transform(val_transforms)\n",
    "    return train_ds, valid_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = prepare_transforms(model_checkpoint, train,valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prep_data(ds_checkpoint=\"davanstrien/flysheet\", model_checkpoint=None):\n",
    "    ds = load_dataset(ds_checkpoint, use_auth_token=True, streaming=False, split='train')\n",
    "    labels = ds.info.features['label'].names\n",
    "    id2label = dict(enumerate(labels))\n",
    "    label2id = {v:k for k,v in id2label.items()}\n",
    "    train,valid, test = prepare_dataset(ds)\n",
    "    train_ds, valid_ds, test_ds = prepare_transforms(model_checkpoint, train, valid, test)\n",
    "    return train_ds, valid_ds, test_ds, id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "import transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(ds_checkpoint, model_checkpoint, num_epochs, save_dir,tune=False):\n",
    "    transformers.logging.set_verbosity_warning()\n",
    "    train_ds, valid_ds, test_ds, id2label, label2id = load_data(ds_checkpoint,model_checkpoint=model_checkpoint)\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_checkpoint, num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                  label2id=label2id, ignore_mismatched_sizes=True)\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "    # if tune:\n",
    "    #     disable_tqdm = True\n",
    "    # else:\n",
    "    #     disable_tqdm = False\n",
    "    args = TrainingArguments(\n",
    "    f\"save_dir/{model_checkpoint}_flyswot\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.1,disable_tqdm=False,\n",
    "    fp16=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir='logs',\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=10,\n",
    "        optim=AdamW,\n",
    "    seed=666,    \n",
    ")\n",
    "    f1 = load_metric(\"f1\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "\n",
    "\n",
    "    trainer = Trainer(model,\n",
    "                      args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor)\n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration davanstrien--flysheet-2cdc8849e04b41c9\n",
      "Reusing dataset parquet (/Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dropping duplicates<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "dropping duplicates\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-1dfba86c98cf68e0.arrow\n",
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-f34fde9b42e1bc61.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">getting ID<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "getting ID\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-3c87c3e3b7dda5fa.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">creating train, valid, test splits<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "creating train, valid, test splits\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">856</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "train has \u001b[1;36m856\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">valid has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "valid has \u001b[1;36m256\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test has \u001b[1;36m111\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 192]) in the checkpoint and torch.Size([8, 192]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = train_model('davanstrien/flysheet', \"facebook/deit-tiny-patch16-224\",0.1,'test',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee685663b2f54781992ff863809337bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d6f56dc9bb4dc68bc2e7b2bbed081f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/951 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5069dc7b15d44264bc157a2152a8f8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/106M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "\n",
    "extractor = AutoFeatureExtractor.from_pretrained(\"davanstrien/convnext-tiny-224_flyswot\")\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"davanstrien/convnext-tiny-224_flyswot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('image-classification',model=model,feature_extractor=extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "from typing import Union, Tuple, Sequence, Set\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    RandomErasing,\n",
    "                                    RandomAutocontrast,\n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    RandomAdjustSharpness,\n",
    "                                    ToTensor)\n",
    "import torch\n",
    "from transformers import AutoFeatureExtractor, TrainingArguments, Trainer\n",
    "from transformers import AutoModelForImageClassification\n",
    "from datasets import load_metric\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "from toolz.dicttoolz import valmap\n",
    "from collections import Counter\n",
    "from toolz import frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration davanstrien--flysheet-2cdc8849e04b41c9\n",
      "Reusing dataset parquet (/Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"davanstrien/flysheet\", use_auth_token=True, streaming=False, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =  '/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r (1).jpg.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r (1).jpg.jpg'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = re.sub(r\"(\\(\\d\\))\",\"\",f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_base_path_deduplicated(x):\n",
    "    f = x['fpath']\n",
    "    f = re.sub(r\"(\\(\\d\\))\",\"\",f)\n",
    "    f = f.split(\".\")[0]\n",
    "    f = f.rstrip()\n",
    "    return {\"clean_path\": re.sub(r\"(\\(\\d\\))\",\"\",f)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_uniques(example, uniques, column='clean_path'):\n",
    "    if example[column] in uniques:\n",
    "        uniques.remove(example[column])\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label', 'fpath'],\n",
       "    num_rows: 2061\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(ds):\n",
    "    ds = ds.map(return_base_path_deduplicated)\n",
    "    uniques = set(ds['clean_path'])\n",
    "    ds = ds.filter(check_uniques, fn_kwargs={\"uniques\":uniques})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c088e7319c45d18fd0b5a9652aa87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcd3fbb504f40ed977f51a329ad6cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = drop_duplicates(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(example):\n",
    "    x = example[\"fpath\"]\n",
    "    x = Path(x).name.split(\"_\")\n",
    "    return {\"id\": \"_\".join(x[:2] if len(x) >= 3 else x[:3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765c9ac575344282b319c0a09b4e29dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(get_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=448x248 at 0x19DE98940>,\n",
       " 'label': 0,\n",
       " 'fpath': '/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/add_ms_10455_fse005r.jpg',\n",
       " 'clean_path': '/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/add_ms_10455_fse005r',\n",
       " 'id': 'add_ms'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label', 'fpath', 'clean_path', 'id'],\n",
       "    num_rows: 1223\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, valid, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_w_stratify(\n",
    "    ds,\n",
    "    test_size: Union[int, float],\n",
    "    train_size: Union[int, float, None] = None,\n",
    "    random_state: Union[int, RandomState, None] = None,\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    labels = ds['label']\n",
    "    label_array = np.array(labels)\n",
    "    train_inds, valid_inds = next(\n",
    "        StratifiedShuffleSplit(\n",
    "            n_splits=2, test_size=test_size, random_state=random_state\n",
    "        ).split(np.zeros(len(labels)), y=label_array)\n",
    "    )\n",
    "    return ds.select(train_inds), ds.select(valid_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = split_w_stratify(ds, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allclose(train.shape, valid.shape,rtol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 25, 2: 108, 3: 93, 0: 36, 6: 139, 1: 30, 4: 164, 7: 16}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_freqs = frequencies(train['label'])\n",
    "train_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([4.5, 3.75, 13.5, 11.625, 20.5, 3.125, 17.375, 2.0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_percentages =  OrderedDict(sorted(valmap(lambda x: x/len(train_freqs),train_freqs).items())).values()\n",
    "train_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([4.5, 3.625, 13.625, 11.75, 20.625, 3.125, 17.375, 1.875])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_freqs = frequencies(valid['label'])\n",
    "valid_percentages = OrderedDict(sorted(valmap(lambda x: x/len(valid_freqs),valid_freqs).items())).values()\n",
    "valid_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allclose(list(train_percentages), list(valid_percentages), atol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train_valid_split_w_stratify(\n",
    "    ds,\n",
    "    valid_size: Union[int,float]=None,\n",
    "    test_size: Union[int, float]=0.3,\n",
    "    train_size: Union[int, float, None] = None,\n",
    "    random_state: Union[int, RandomState, None] = None,\n",
    ") -> Tuple[Dataset,Dataset, Dataset]:\n",
    "    train, valid_test = split_w_stratify(ds, test_size=test_size)\n",
    "    valid, test = split_w_stratify(valid_test, test_size=test_size)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = train_valid_split_w_stratify(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(ds):\n",
    "    print(\"Preparing dataset...\")\n",
    "    print(\"dropping duplicates...\")\n",
    "    ds = drop_duplicates(ds)\n",
    "    print(\"getting ID...\")\n",
    "    ds = ds.map(get_id)    \n",
    "    print(\"creating train, valid, test splits...\")\n",
    "    train, valid, test = train_valid_split_w_stratify(ds)\n",
    "    data = {\"train\": train, \n",
    "            \"valid\": valid, \n",
    "            \"test\": test}\n",
    "    for k,v  in data.items():\n",
    "        print(f\"{k} has {len(v)} examples\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration davanstrien--flysheet-2cdc8849e04b41c9\n",
      "Reusing dataset parquet (/Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"davanstrien/flysheet\", use_auth_token=True, streaming=False, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dropping duplicates<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "dropping duplicates\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-1dfba86c98cf68e0.arrow\n",
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-f34fde9b42e1bc61.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">getting ID<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "getting ID\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-3c87c3e3b7dda5fa.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">creating train, valid, test splits<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "creating train, valid, test splits\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">856</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "train has \u001b[1;36m856\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">valid has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "valid has \u001b[1;36m256\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "test has \u001b[1;36m111\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['image', 'label', 'fpath', 'clean_path', 'id'],\n",
       "     num_rows: 856\n",
       " }),\n",
       " 'valid': Dataset({\n",
       "     features: ['image', 'label', 'fpath', 'clean_path', 'id'],\n",
       "     num_rows: 256\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['image', 'label', 'fpath', 'clean_path', 'id'],\n",
       "     num_rows: 111\n",
       " })}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_dataset(ds)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"davanstrien/vit-base-patch16-224-in21k-base-manuscripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_transforms(model_checkpoint, train_ds, valid_ds, test_ds=None):\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "    normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "    _train_transforms = Compose(\n",
    "            [\n",
    "                Resize((feature_extractor.size,feature_extractor.size)),\n",
    "                RandomAdjustSharpness(0.1),\n",
    "                RandomAutocontrast(),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "                RandomErasing()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    _val_transforms = Compose(\n",
    "            [\n",
    "                Resize((feature_extractor.size, feature_extractor.size)),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def train_transforms(examples):\n",
    "        examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "        return examples\n",
    "\n",
    "    def val_transforms(examples):\n",
    "        examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "        return examples\n",
    "    if test_ds is not None:\n",
    "        test_ds.set_transform(val_transforms)\n",
    "    train_ds.set_transform(train_transforms)\n",
    "    valid_ds.set_transform(val_transforms)\n",
    "    return train_ds, valid_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = prepare_transforms(model_checkpoint, train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_data(ds_checkpoint=\"davanstrien/flysheet\", model_checkpoint=None):\n",
    "    ds = load_dataset(ds_checkpoint, use_auth_token=True, streaming=False, split='train')\n",
    "    labels = ds.info.features['label'].names\n",
    "    id2label = dict(enumerate(labels))\n",
    "    label2id = {v:k for k,v in id2label.items()}\n",
    "    train, valid, test = train_valid_split_w_stratify(ds)\n",
    "    train_ds, valid_ds, test_ds = prepare_transforms(model_checkpoint, train, valid, test)\n",
    "    return train_ds, valid_ds, test_ds, id2label, label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "import transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(ds_checkpoint, model_checkpoint, num_epochs, save_dir,tune=False):\n",
    "    transformers.logging.set_verbosity_warning()\n",
    "    train_ds, valid_ds, test_ds, id2label, label2id = load_data(ds_checkpoint,model_checkpoint=model_checkpoint)\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_checkpoint, num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                  label2id=label2id, ignore_mismatched_sizes=True)\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "    if tune:\n",
    "        disable_tqdm = True\n",
    "    else:\n",
    "        disable_tqdm = False\n",
    "    args = TrainingArguments(\n",
    "    f\"save_dir/{model_checkpoint}_flyswot\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.1,disable_tqdm=disable_tqdm,\n",
    "    fp16=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir='logs',\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=10,optim=AdamW,\n",
    "    seed=666,    \n",
    ")\n",
    "    f1 = load_metric(\"f1\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "    import torch\n",
    "\n",
    "    trainer = Trainer(model,\n",
    "                      args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration davanstrien--flysheet-2cdc8849e04b41c9\n",
      "Reusing dataset parquet (/Users/dvanstrien/.cache/huggingface/datasets/parquet/davanstrien--flysheet-2cdc8849e04b41c9/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295ac18be7b843b8920b621b1f46cfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237598a503d84124a6c2b47c0609a07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/68.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708c5d87db274cafb73325d4c13b3718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/21.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 192]) in the checkpoint and torch.Size([8, 192]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_model('davanstrien/flysheet', \"facebook/deit-tiny-patch16-224\",0.1,'test',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "class ResnetConfig(PretrainedConfig):\n",
    "    model_type = \"convnext\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels=3,\n",
    "        heads: int = 8,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.num_channels = num_channels\n",
    "        self.heads:List[int] = heads\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50d_config = ResnetConfig(heads=[3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetConfig {\n",
       "  \"heads\": [\n",
       "    3,\n",
       "    2\n",
       "  ],\n",
       "  \"model_type\": \"convnext\",\n",
       "  \"num_channels\": 3,\n",
       "  \"transformers_version\": \"4.16.2\"\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50d_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel\n",
    "from timm.models.resnet import ResNet\n",
    "\n",
    "\n",
    "class ResnetModel(PreTrainedModel):\n",
    "    config_class = ResnetConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        block_layer = BLOCK_MAPPING[config.block_type]\n",
    "        self.model = ResNet(\n",
    "        )\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return self.model.forward_features(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ConvNextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aff0c5f73d14c67b5849b04a0d49649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/68.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"facebook/convnext-base-384-22k-1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/convnext-base-384-22k-1k were not used when initializing ConvNextModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ConvNextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ConvNextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ConvNextModel.from_pretrained(\"facebook/convnext-base-384-22k-1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, first_bn=True, bn_final=False,\n",
    "                lin_first=False, y_range=None):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and out `n_out` classes.\"\n",
    "    if concat_pool: nf *= 2\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    bns = [first_bn] + [True]*len(lin_ftrs[1:])\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,bn,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=bn, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModel(Module):\n",
    "    \"A two-headed model given a `body` and `n` output features\"\n",
    "\n",
    "    def __init__(self, body: nn.Sequential, n: L):\n",
    "        nf = num_features_model(nn.Sequential(*body.children()))  #* (2)\n",
    "        self.body = body\n",
    "        self.compressed_labels = create_head(nf, n[0])\n",
    "        self.label = create_head(nf, n[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.body(x)\n",
    "        compressed_labels = self.compressed_labels(y)\n",
    "        label = self.label(y)\n",
    "        return [compressed_labels, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ConvNextPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNextForImageClassification(ConvNextPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.num_labels_1 = config.num_labels_1\n",
    "        self.num_labels_2 = confgi.num_labels_2\n",
    "        self.convnext = ConvNextModel(config)\n",
    "\n",
    "        # Classifier head\n",
    "        self.classifier1 = (\n",
    "            nn.Linear(config.hidden_sizes[-1], config.num_labels_1) if config.num_labels > 0 else nn.Identity()\n",
    "        )\n",
    "        self.classifier2 = (\n",
    "            nn.Linear(config.hidden_sizes[-1], config.num_labels_2) if config.num_labels > 0 else nn.Identity()\n",
    "        )\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "    def forward(self, pixel_values=None, labels=None, output_hidden_states=None, return_dict=None):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.convnext(pixel_values, output_hidden_states=output_hidden_states, return_dict=return_dict)\n",
    "\n",
    "        pooled_output = outputs.pooler_output if return_dict else outputs[1]\n",
    "\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return ConvNextClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model management"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
